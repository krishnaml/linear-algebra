{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The first step is to calculate the mean values of each column\n",
    "  - M = mean(A)\n",
    "- center the values in each column by subtracting the mean column value  \n",
    "  - C=A−M\n",
    "- A covariance matrix is a calculation of covariance of a given matrix\n",
    "  - V = cov(C)\n",
    "- calculate the eigendecomposition of the covariance matrix V\n",
    "  - values, vectors = eig(V )\n",
    "- select k eigenvectors, called principal components, that have the k largest eigenvalues.\n",
    "  - B = select(values, vectors)\n",
    "- Once chosen, data can be projected into the subspace via matrix multiplication\n",
    "  - P = B^T · A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "[[ 0.70710678 -0.70710678]\n",
      " [ 0.70710678  0.70710678]]\n",
      "[8. 0.]\n",
      "[[-2.82842712  0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.82842712  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# principal component analysis\n",
    "\n",
    "# define matrix\n",
    "A = np.array([\n",
    "  [1, 2],\n",
    "  [3, 4],\n",
    "[5, 6]])\n",
    "print(A)\n",
    "# column means\n",
    "M = np.mean(A.T, axis=1)\n",
    "# center columns by subtracting column means \n",
    "C=A-M\n",
    "# calculate covariance matrix of centered matrix \n",
    "V = np.cov(C.T)\n",
    "# factorize covariance matrix\n",
    "values, vectors = np.linalg.eig(V)\n",
    "print(vectors)\n",
    "print(values)\n",
    "# project data\n",
    "P = vectors.T.dot(C.T)\n",
    "print(P.T)\n",
    "\n",
    "# Interestingly, we can see that only the first eigenvector is required, suggesting that \n",
    "# we could project our 3 × 2 matrix onto a 3 × 1 matrix with little loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "[[ 0.70710678  0.70710678]\n",
      " [ 0.70710678 -0.70710678]]\n",
      "[8.00000000e+00 2.25080839e-33]\n",
      "[[-2.82842712e+00  2.22044605e-16]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 2.82842712e+00 -2.22044605e-16]]\n"
     ]
    }
   ],
   "source": [
    "# principal component analysis with scikit-learn\n",
    "from sklearn.decomposition import PCA\n",
    "# define matrix\n",
    "A = np.array([\n",
    "  [1, 2],\n",
    "  [3, 4],\n",
    "  [5, 6]])\n",
    "print(A)\n",
    "# create the transform\n",
    "pca = PCA(2)\n",
    "# fit transform\n",
    "pca.fit(A)\n",
    "# access values and vectors\n",
    "print(pca.components_)\n",
    "print(pca.explained_variance_)\n",
    "# transform data\n",
    "B = pca.transform(A)\n",
    "print(B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
